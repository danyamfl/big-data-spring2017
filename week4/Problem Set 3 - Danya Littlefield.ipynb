{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data: Problem Set 3\n",
    "\n",
    "### Danya Littlefield\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "**1** - Using the Twitter REST API, collect Tweets from Boston for 30 min. Note how you set the time in the above example (in the **run_all()** function), it was in seconds. How would you do that here? \n",
    "\n",
    "**2** - Create a Pie Chart showing a summary of tweets by user location. Please clean up the data so that multiple variations of the same location name are replaced with one variation.\n",
    "\n",
    "**3** - Create a Scatterplot showing all of the tweets that had a latitude and longitude.\n",
    "\n",
    "**4** - Pick a search term, such as *Trump* or *#Trump* and collect 15 minutes of tweets on it. Use the same lat/lon for Boston as you used above.\n",
    "\n",
    "**5** - Export the entirety of your scraped Twitter datasets (one with a search term, one without) to two CSV files. We will be checking this CSV file for duplicates. So clean your file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from twython import Twython\n",
    "\n",
    "# Imports the keys from the python file\n",
    "from twitter_key import api_key, api_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assigns the keys to the variables\n",
    "APP_KEY = api_key\n",
    "APP_SECRET = api_secret\n",
    "\n",
    "# Create a Twython object called Twitter\n",
    "# Set this up using your Twitter Keys\n",
    "# Say we are going to use OAuth 2\n",
    "twython_setup = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "\n",
    "# Get an OAuth2 access token, save as variable so we can launch our \n",
    "OAUTH2_ACCESS_TOKEN = twython_setup.obtain_access_token()\n",
    "\n",
    "# Create a Twython Object we will use for our access to the API\n",
    "my_twython = Twython(APP_KEY, access_token=OAUTH2_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input the search term you want to search on\n",
    "search_term='' # SET A SEARCH TERM LIKE 'TRUMP'\n",
    "# CAN LEAVE search_term BLANK IF YOU WANT ALL TWEETS NEAR A SPECIFIC LOCATION\n",
    "# Setup a Lat Lon\n",
    "latlong=[42.354046, -71.068202] # A point on the Boston Common\n",
    "# Setup a search distance\n",
    "distance='15mi'\n",
    "# Set result type (can be 'recent', 'popular', or 'mixed')\n",
    "type_of_result='recent'\n",
    "# Set number of results (up to 100, remember you can only get 450 in 15 minutes)\n",
    "number_of_tweets=30\n",
    "\n",
    "\n",
    "# Fetches tweets with a given query at a given lat-long.\n",
    "def get_tweets_by_location( latlong=None ):\n",
    "    # Uses the search function to hit the APIs endpoints and look for recent tweets within the area\n",
    "    results = my_twython.search(q=search_term, geocode=str(latlong[0])+','+str(latlong[1])+','+ distance, result_type=type_of_result, count=number_of_tweets)\n",
    "    # Returns the only the statuses from the resulting JSON\n",
    "    return results['statuses']\n",
    "\n",
    "# test run our function\n",
    "get_tweets_by_location(latlong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'm going to set up the rest of the data scraper as in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does pretty much what its long name suggests.\n",
    "def get_lots_of_tweets( latlong ):\n",
    "    # Create a dictionary to parse the JSON\n",
    "    all_tweets = {}\n",
    "    \n",
    "    # We will be hitting the API a number of times within the total time\n",
    "    total_time = 10\n",
    "    \n",
    "    # Everytime we hit the API we subtract time from the total\n",
    "    remaining_seconds = total_time\n",
    "    interval = 5\n",
    "    while remaining_seconds > 0: # loop and run the function while remaining seconds is greater than zero\n",
    "        added = 0\n",
    "        # Hit the Twitter API using our function\n",
    "        new_tweets = get_tweets_by_location(latlong) # we set latlong above!\n",
    "        # Parse the resulting JSON, and save the rest of the raw content\n",
    "        for tweet in new_tweets:\n",
    "            tid = tweet['id']\n",
    "            if tid not in all_tweets:\n",
    "                properties = {}\n",
    "                if tweet['coordinates'] != None:\n",
    "                    properties['lat'] = tweet['coordinates']['coordinates'][0]\n",
    "                    properties['lon'] = tweet['coordinates']['coordinates'][1]\n",
    "                else:\n",
    "                    properties['lat'] = None\n",
    "                    properties['lon'] = None\n",
    "                properties['location'] = tweet['user']['location'] #This will get us the location associated with the profile\n",
    "                properties['tweet_id'] = tid\n",
    "                properties['content'] = tweet['text']\n",
    "                properties['user'] = tweet['user']['id']\n",
    "                properties['raw_source'] = tweet\n",
    "                properties['data_point'] = 'none'\n",
    "                properties['time'] = tweet['created_at']\n",
    "                all_tweets[ tid ] = properties\n",
    "                added += 1\n",
    "        print(\"At %d seconds, added %d new tweets, for a total of %d\" % ( total_time - remaining_seconds, added, len( all_tweets )))\n",
    "        # We wait a few seconds and hit the API again\n",
    "        time.sleep(interval)\n",
    "        remaining_seconds -= interval\n",
    "    print(str(len(all_tweets)) + ' Tweets retrieved.')\n",
    "    # We return the final dictionary to work with in Python\n",
    "    return all_tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
